{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier for Sonar Readings\n",
    "\n",
    "In this document I will be copying code from https://machinelearningmastery.com/building-a-binary-classification-model-in-pytorch/. This code uses PyTorch to design and train a neural network on training data. It will then evaluate the performance of the neural network using a k-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset describes data from a sonar chirp which returns bouncing off of different services. There are 60 input variables which each have the strength of the returns at different angles. The classification problem will determine whether it has bounced off of a rock or a metal cylinder\n",
    "\n",
    "First we need to import pandas so that we can read in the dataset and set the X as the independent variables and the Y as the label or dependent variable which in this case is whether it is a rock or a metal cylinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None) #read file in\n",
    "X = data.iloc[:, 0:60] #all independent variables\n",
    "y = data.iloc[:, 60] #dependent variable or label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label which is in the y variable needs to be converted froma a string to a numeric label. As there is only 2 labels, 'M' and 'R' these can be converted to 1 and 0 respectively. \n",
    "\n",
    "This can be done using sklearn and the encoder function which will do this automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check this has been done correctly we can use encoder.classes_ to check the classes and we can also print y to see the data outputs. When using encoder.classes_ this should us 'M' and 'R'. When printing y, we should see 1's and 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'R']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen this has worked and we have received our expected output. The 0 represents 'M' and the 1 represents the 'R'.\n",
    "\n",
    "Next we need to convert these in to PyTorch tensors so that we can feed it into our PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be creating a 3 layer neural network model that only has 1 hidden layer. As this model has 60 pieces of input data to predict one binary variable. As we want to make a wide model with one hidden layer, a hidden layer of 180 neurons would be a good model. 180 is a three times the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new class which creates a model with one hidden layer\n",
    "class Wide(nn.Module):\n",
    "    #initialiser\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #creates linear transformation from input layer to hidden layer\n",
    "        self.hidden = nn.Linear(60, 180)\n",
    "        self.relu = nn.ReLU()\n",
    "        #creates linear transformation from hidden layer to output layer\n",
    "        self.output = nn.Linear(180, 1)\n",
    "        #applies sigmoid function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    #method to move data from left layer to right layer, takes in the data as paramater\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are alos going to create a second model which uses 3 hidden layers. This is called a deeper model as it has more than one hidden layer. This model will have 3 layers each with 60 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that the 2 models have similar number of parameters by running the following code. When this code is run we should get 2 numbers which are vaguely similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11161\n",
      "11041\n"
     ]
    }
   ],
   "source": [
    "# Compare model sizes\n",
    "model1 = Wide()\n",
    "model2 = Deep()\n",
    "print(sum([x.reshape(-1).shape[0] for x in model1.parameters()]))  # 11161\n",
    "print(sum([x.reshape(-1).shape[0] for x in model2.parameters()]))  # 11041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the above cell the models have been created successfully as the two numbers are similar.\n",
    "\n",
    "Now that both models have been created we now need ot train the data using our testing set. A testing method that we can use is called k-fold cross validation. This splits a large dataset into k amount of portions and takes one portion as the test set while the k-1 portions are the training set. There will be k number of combinations and the size of the training set will increase each time. \n",
    "\n",
    "Scikit-learn will use stratified k fold which means when seperating the data into the portions, it will ensure that there is a fair distribution of data in each portion.\n",
    "\n",
    "First we need to import the needed libraries from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m kfold\u001b[38;5;241m.\u001b[39msplit(X, y):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# create model, train, and get accuracy\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m Wide()\n\u001b[1;32m----> 7\u001b[0m     acc \u001b[38;5;241m=\u001b[39m model_train(model, X[train], y[train], X[test], y[test])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy (wide): \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m acc)\n\u001b[0;32m      9\u001b[0m     cv_scores\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_train' is not defined"
     ]
    }
   ],
   "source": [
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Wide()\n",
    "    acc = model_train(model, X[train], y[train], X[test], y[test])\n",
    "    print(\"Accuracy (wide): %.2f\" % acc)\n",
    "    cv_scores.append(acc)\n",
    "\n",
    "# evaluate the model\n",
    "acc = np.mean(cv_scores)\n",
    "std = np.std(cv_scores)\n",
    "print(\"Model accuracy: %.2f%% (+/- %.2f%%)\" % (acc*100, std*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
